\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{stackGAN,attribute2image}
\citation{deepMSE,genVSD}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{deepSeg2015}
\citation{deepConv2014}
\citation{deepSeg2015}
\citation{deepSeg2015}
\citation{densebox2015}
\citation{track2015}
\citation{deconv2015}
\citation{rnn2012}
\citation{rnn2011}
\citation{gradient1994}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Generating video sequence based on a given pre-condition (sentence description).\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{problem}{{1}{2}{Generating video sequence based on a given pre-condition (sentence description).\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}}
\newlabel{background}{{2}{2}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Fully Convolutional Networks (FCN)}{2}{subsection.2.1}}
\newlabel{fully_convolutional_networks}{{2.1}{2}{Fully Convolutional Networks (FCN)}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Recurrent Neural Networks (RNN)}{2}{subsection.2.2}}
\newlabel{recurrent_neural_networks}{{2.2}{2}{Recurrent Neural Networks (RNN)}{subsection.2.2}{}}
\citation{lstm1997}
\citation{encoder2014}
\citation{rnn2014}
\citation{gan2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Long Short Term Memory (LSTM)}{3}{subsubsection.2.2.1}}
\newlabel{long_short_term_memory}{{2.2.1}{3}{Long Short Term Memory (LSTM)}{subsubsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Gated Recurrent Unit (GRU)}{3}{subsubsection.2.2.2}}
\newlabel{gated_recurrent_unit}{{2.2.2}{3}{Gated Recurrent Unit (GRU)}{subsubsection.2.2.2}{}}
\citation{faceGan2015,condGan2014}
\citation{stackGAN}
\citation{stackGAN}
\citation{stackGAN}
\citation{bayes2014,learn2016}
\citation{tutorial2016,autoEncod2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces GRU Architecture.\relax }}{4}{figure.caption.3}}
\newlabel{fig:gru}{{2}{4}{GRU Architecture.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Generative Adversarial Networks (GAN)}{4}{subsection.2.3}}
\newlabel{generative_adversarial_networks}{{2.3}{4}{Generative Adversarial Networks (GAN)}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Our Approach}{4}{section.3}}
\newlabel{our_approach}{{3}{4}{Our Approach}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Stacked Adversarial Network}{4}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Stage-I GAN}{4}{subsubsection.3.1.1}}
\citation{fineGrain2016}
\citation{autoEncod2014}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The architecture of the StackGAN from \cite  {stackGAN}. The Stage-I generator draws a low resolution image by sketching rough shape and basic colors of the object from the given text and painting the background from a random noise vector. The Stage-II generator generates a high resolution image with photo-realistic details by conditioning on both the Stage-I result and the text again.\relax }}{5}{figure.caption.4}}
\newlabel{stackgan}{{3}{5}{The architecture of the StackGAN from \cite {stackGAN}. The Stage-I generator draws a low resolution image by sketching rough shape and basic colors of the object from the given text and painting the background from a random noise vector. The Stage-II generator generates a high resolution image with photo-realistic details by conditioning on both the Stage-I result and the text again.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Architecture}{5}{section*.5}}
\citation{percep2016,deepRes2016}
\citation{autoEncod2014}
\citation{rFCN}
\citation{rFCN}
\citation{rFCN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Stage-II GAN}{6}{subsubsection.3.1.2}}
\@writefile{toc}{\contentsline {paragraph}{Model Architecture}{6}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Recurrent Fully Convolutional Network}{6}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Convolutional Gated Recurrent Unit (Conv-GRU)}{6}{subsubsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The architecture of RFC-VGG from \cite  {rFCN}. Images are fed frame by frame into a recurrent FCN. A Conv-GRU layer is applied on the feature maps produced by the preceding network at each frame. The output of this layer goes to one more convolutional layer to generate heat maps. Finally, a deconvolution layer up-samples the heat map to the desired spatial size.\relax }}{7}{figure.caption.7}}
\newlabel{recurrent_fcn}{{4}{7}{The architecture of RFC-VGG from \cite {rFCN}. Images are fed frame by frame into a recurrent FCN. A Conv-GRU layer is applied on the feature maps produced by the preceding network at each frame. The output of this layer goes to one more convolutional layer to generate heat maps. Finally, a deconvolution layer up-samples the heat map to the desired spatial size.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Recurrent Stacked Generative Adversarial Network (RSGAN)}{7}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}}
\newlabel{experiments}{{4}{7}{Experiments}{section.4}{}}
\citation{NTU}
\citation{uCF101}
\citation{improvGan2016}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The proposed Recurrent Stacked Generative network (RSGAN). The recurrent adversarial network modules at the first stage (RGAN-1) take the encoded pre-condition and a random vector $z_t$ and then produces a low resolution ($64 \times 64$) size image. The modules at stage-2 (RGAN-2) takes the generated image at stage-1 and the encoded pre-condition to generate a high resolution image ($256 \times 256$).\relax }}{8}{figure.caption.8}}
\newlabel{RSGAN}{{5}{8}{The proposed Recurrent Stacked Generative network (RSGAN). The recurrent adversarial network modules at the first stage (RGAN-1) take the encoded pre-condition and a random vector $z_t$ and then produces a low resolution ($64 \times 64$) size image. The modules at stage-2 (RGAN-2) takes the generated image at stage-1 and the encoded pre-condition to generate a high resolution image ($256 \times 256$).\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Datasets}{8}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}NTU RGB+D Action Recognition Dataset}{8}{subsubsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}UCF-101 Dataset}{8}{subsubsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Evaluation Metrics}{8}{subsection.4.2}}
\citation{batchNorm2014}
\citation{rectifier2013,rectifierConv2015}
\citation{imgRecog2014}
\citation{adaDelta2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Methods and Implementation}{9}{subsection.4.3}}
\@writefile{toc}{\contentsline {paragraph}{StanGan Implementaion}{9}{section*.9}}
\@writefile{toc}{\contentsline {paragraph}{Conv-GRU Implementaion}{9}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Proposed Conv-GRU networks. $F(n)$ denotes filter size of $n \times n$. $P(n)$ denotes total of $n$ zero padding around the feature map. $S(n)$ denotes stride of length $n$ for the convolution. $D(n)$ denotes number of output feature maps from a particular layer $n$ for a layer (number of feature maps is same as previous layer if $D$ is not mentioned).\relax }}{9}{figure.caption.11}}
\newlabel{conv-gru}{{6}{9}{Proposed Conv-GRU networks. $F(n)$ denotes filter size of $n \times n$. $P(n)$ denotes total of $n$ zero padding around the feature map. $S(n)$ denotes stride of length $n$ for the convolution. $D(n)$ denotes number of output feature maps from a particular layer $n$ for a layer (number of feature maps is same as previous layer if $D$ is not mentioned).\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Qualitative Results}{9}{subsection.4.4}}
\@writefile{toc}{\contentsline {paragraph}{NTU RGB+D Action Recognition Dataset}{9}{section*.12}}
\citation{recVEBA}
\newlabel{fig:1a}{{7a}{10}{Subfigure 7a}{subfigure.7.1}{}}
\newlabel{sub@fig:1a}{{(a)}{a}{Subfigure 7a\relax }{subfigure.7.1}{}}
\newlabel{fig:1b}{{7b}{10}{Subfigure 7b}{subfigure.7.2}{}}
\newlabel{sub@fig:1b}{{(b)}{b}{Subfigure 7b\relax }{subfigure.7.2}{}}
\newlabel{fig:1c}{{7c}{10}{Subfigure 7c}{subfigure.7.3}{}}
\newlabel{sub@fig:1c}{{(c)}{c}{Subfigure 7c\relax }{subfigure.7.3}{}}
\newlabel{fig:1b}{{7d}{10}{Subfigure 7d}{subfigure.7.4}{}}
\newlabel{sub@fig:1b}{{(d)}{d}{Subfigure 7d\relax }{subfigure.7.4}{}}
\newlabel{fig:1b}{{7e}{10}{Subfigure 7e}{subfigure.7.5}{}}
\newlabel{sub@fig:1b}{{(e)}{e}{Subfigure 7e\relax }{subfigure.7.5}{}}
\newlabel{fig:1b}{{7f}{10}{Subfigure 7f}{subfigure.7.6}{}}
\newlabel{sub@fig:1b}{{(f)}{f}{Subfigure 7f\relax }{subfigure.7.6}{}}
\newlabel{fig:1b}{{7g}{10}{Subfigure 7g}{subfigure.7.7}{}}
\newlabel{sub@fig:1b}{{(g)}{g}{Subfigure 7g\relax }{subfigure.7.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Example results by our proposed RSGAN. The first row is the ground truth, and the second row is the output frame of RSGAN.\relax }}{10}{figure.caption.13}}
\newlabel{fig:1}{{7}{10}{Example results by our proposed RSGAN. The first row is the ground truth, and the second row is the output frame of RSGAN.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces { Action: Drink water.}}}{10}{subfigure.7.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Action: Drop.}}}{10}{subfigure.7.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Action: Point finger at the other person.}}}{10}{subfigure.7.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Action: Reading.}}}{10}{subfigure.7.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Action: Slapping other person.}}}{10}{subfigure.7.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Action: Tablet.}}}{10}{subfigure.7.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {Action: Writing.}}}{10}{subfigure.7.7}}
\@writefile{toc}{\contentsline {paragraph}{UCF-101 Dataset}{10}{section*.14}}
\newlabel{fig:1aUCF101}{{8a}{10}{Subfigure 8a}{subfigure.8.1}{}}
\newlabel{sub@fig:1aUCF101}{{(a)}{a}{Subfigure 8a\relax }{subfigure.8.1}{}}
\newlabel{fig:1bUCF101}{{8b}{10}{Subfigure 8b}{subfigure.8.2}{}}
\newlabel{sub@fig:1bUCF101}{{(b)}{b}{Subfigure 8b\relax }{subfigure.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Example results by our proposed RSGAN. The first coulmn is a ground truth frame of the input action class, and the other columns are the output frames of RSGAN.\relax }}{10}{figure.caption.15}}
\newlabel{fig:1}{{8}{10}{Example results by our proposed RSGAN. The first coulmn is a ground truth frame of the input action class, and the other columns are the output frames of RSGAN.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces { }}}{10}{subfigure.8.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces { }}}{10}{subfigure.8.2}}
\bibstyle{abbrv}
\bibdata{project_report}
\bibcite{gradient1994}{{1}{}{{}}{{}}}
\bibcite{encoder2014}{{2}{}{{}}{{}}}
\bibcite{rnn2014}{{3}{}{{}}{{}}}
\bibcite{tutorial2016}{{4}{}{{}}{{}}}
\bibcite{faceGan2015}{{5}{}{{}}{{}}}
\bibcite{gan2014}{{6}{}{{}}{{}}}
\bibcite{deepRes2016}{{7}{}{{}}{{}}}
\bibcite{lstm1997}{{8}{}{{}}{{}}}
\bibcite{densebox2015}{{9}{}{{}}{{}}}
\bibcite{batchNorm2014}{{10}{}{{}}{{}}}
\bibcite{percep2016}{{11}{}{{}}{{}}}
\bibcite{bayes2014}{{12}{}{{}}{{}}}
\bibcite{autoEncod2016}{{13}{}{{}}{{}}}
\bibcite{deepSeg2015}{{14}{}{{}}{{}}}
\bibcite{rectifier2013}{{15}{}{{}}{{}}}
\bibcite{deepMSE}{{16}{}{{}}{{}}}
\bibcite{condGan2014}{{17}{}{{}}{{}}}
\bibcite{recVEBA}{{18}{}{{}}{{}}}
\bibcite{deconv2015}{{19}{}{{}}{{}}}
\bibcite{learn2016}{{20}{}{{}}{{}}}
\bibcite{fineGrain2016}{{21}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion and Future Works}{11}{section.5}}
\newlabel{conclusion}{{5}{11}{Conclusion and Future Works}{section.5}{}}
\bibcite{autoEncod2014}{{22}{}{{}}{{}}}
\bibcite{improvGan2016}{{23}{}{{}}{{}}}
\bibcite{NTU}{{24}{}{{}}{{}}}
\bibcite{deepConv2014}{{25}{}{{}}{{}}}
\bibcite{imgRecog2014}{{26}{}{{}}{{}}}
\bibcite{uCF101}{{27}{}{{}}{{}}}
\bibcite{rnn2011}{{28}{}{{}}{{}}}
\bibcite{rFCN}{{29}{}{{}}{{}}}
\bibcite{rnn2012}{{30}{}{{}}{{}}}
\bibcite{genVSD}{{31}{}{{}}{{}}}
\bibcite{track2015}{{32}{}{{}}{{}}}
\bibcite{rectifierConv2015}{{33}{}{{}}{{}}}
\bibcite{attribute2image}{{34}{}{{}}{{}}}
\bibcite{adaDelta2012}{{35}{}{{}}{{}}}
\bibcite{stackGAN}{{36}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
